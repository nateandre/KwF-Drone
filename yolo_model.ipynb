{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo Darknet-19 model\n",
    "\n",
    "We are the yolo2 Darknet-19 forward propagation as we believe it is the optimal tradeoff between predictive performance and computational performance. Further, given that this model is intended to be used for onboard processing, we are further reducing the complexity of the model by having it only learn a single bounding box shape, bounding the number of channels of the output at 29 - thus the output shape will be 19x19x29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 608, 608, 3)\n",
      "(2, 19, 19, 29)\n"
     ]
    }
   ],
   "source": [
    "images = np.load(\"../data/kwf/images.npy\")\n",
    "encodings = np.load(\"../data/kwf/encodings.npy\")\n",
    "print(images.shape)\n",
    "print(encodings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Forward Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder values for input X,y data\n",
    "def get_placeholders(x_h,x_w,x_c,y_h,y_w,y_c):\n",
    "    \"\"\"\n",
    "    x_h: Height for x input \n",
    "    x_w: Width for x input\n",
    "    x_c: Channels for x input\n",
    "    y_h: Height for y input\n",
    "    y_w: Width for y input\n",
    "    y_c: Channels for y input\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, name=\"X\", shape=(None,x_h,x_w,x_c))\n",
    "    y = tf.placeholder(tf.float32, name=\"y\", shape=(None,y_h,y_w,y_c))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constant layer for 2d convolution, batch norm, and activation\n",
    "def conv(the_input,layer,f,ks):\n",
    "    \"\"\"\n",
    "    the_input: the layer which will be used as input in conv layer\n",
    "    layer: specifies the layer number for naming sections of graph\n",
    "    f (filters): the number of filters to be used for conv layer\n",
    "    ks (kernel_size): kernel size for conv2d layer\n",
    "    Note - conv2d layers all use padding\n",
    "    \"\"\"\n",
    "    layer = str(layer)\n",
    "    Z = tf.layers.conv2d(the_input,filters=f,kernel_size=[ks,ks],strides=(1,1),padding=\"same\",name=\"Z\"+layer,kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    Bn = tf.layers.batch_normalization(Z,name=\"Bn\"+layer)\n",
    "    A = tf.nn.leaky_relu(Bn,alpha=0.1,name=\"A\"+layer)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the forward pass based on Darket-19\n",
    "# Note - forward pass will use leaky_relu\n",
    "def forward_pass(X):\n",
    "    input_layer = tf.reshape(X,[-1,608,608,3]) # Input shape of images\n",
    "    S1 = conv(input_layer,1,32,3)\n",
    "    P1 = tf.layers.max_pooling2d(S1,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P1\") # 224x224\n",
    "    S2 = conv(P1,2,64,3)\n",
    "    P2 = tf.layers.max_pooling2d(S2,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P2\") # 112x112\n",
    "    S3 = conv(P2,3,128,3)\n",
    "    S4 = conv(S3,4,64,1)\n",
    "    S5 = conv(S4,5,128,3)\n",
    "    P5 = tf.layers.max_pooling2d(S5,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P5\") # 56x56\n",
    "    S6 = conv(P5,6,256,3)\n",
    "    S7 = conv(S6,7,128,1)\n",
    "    S8 = conv(S7,8,256,3)\n",
    "    P8 = tf.layers.max_pooling2d(S8,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P8\") # 28x28\n",
    "    S9 = conv(P8,9,512,3)\n",
    "    S10 = conv(S9,10,256,1)\n",
    "    S11 = conv(S10,11,512,3)\n",
    "    S12 = conv(S11,12,256,1)\n",
    "    S13 = conv(S12,13,512,3)\n",
    "    P13 = tf.layers.max_pooling2d(S13,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P13\") #14x14\n",
    "    S14 = conv(P13,14,1024,3)\n",
    "    S15 = conv(S14,15,512,1)\n",
    "    S16 = conv(S15,16,1024,3)\n",
    "    S17 = conv(S16,17,512,1)\n",
    "    S18 = conv(S17,18,2014,3)\n",
    "    # Final layer - no batch norm, linear activation\n",
    "    S19 = tf.layers.conv2d(S18,filters=29,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"S19\",activation=None)\n",
    "    return S19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z shape: (1, 19, 19, 29)\n"
     ]
    }
   ],
   "source": [
    "# Testing forward prop\n",
    "tf.reset_default_graph()\n",
    "ax = np.zeros((1,608,608,3))\n",
    "X,y = get_placeholders(608,608,3,19,19,29)\n",
    "Z19 = forward_pass(X)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    aZ = sess.run(Z19,feed_dict={X:ax})\n",
    "    print(\"Z shape:\", str(aZ.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavily penalizes negative predictions for height and weight\n",
    "def cost_function(Z,y,coord=5,noobj=0.25):\n",
    "    \"\"\"\n",
    "    Z - shape (None,19,19,29)\n",
    "    y - shape (None,19,19,29)\n",
    "    \"\"\"\n",
    "    c_mask_true = y[:,:,:,0:1] > 0\n",
    "    c_mask_false = y[:,:,:,0:1] < 1\n",
    "    confidence = tf.boolean_mask(Z[:,:,:,0:1],c_mask_true)\n",
    "    confidence2 = tf.boolean_mask(y[:,:,:,0:1],c_mask_true)\n",
    "    end = tf.square(confidence - confidence2)\n",
    "    end2 = tf.reduce_sum(end)\n",
    "    return (confidence,confidence2,end,end2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1310066e-04 1.3068070e-04 1.1917770e-04 1.0849191e-04 1.2012606e-04\n",
      " 1.3822227e-04 7.3459953e-05 3.7159654e-05]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0.99977374 0.9997387  0.9997617  0.99978304 0.9997598  0.99972355\n",
      " 0.99985313 0.99992573]\n",
      "7.9983196\n"
     ]
    }
   ],
   "source": [
    "# testing cost function\n",
    "tf.reset_default_graph()\n",
    "ax = images[0,:,:,:]\n",
    "ax.shape = (1,608,608,3)\n",
    "ay = encodings[0,:,:,:]\n",
    "ay.shape = (1,19,19,29)\n",
    "\n",
    "X,y = get_placeholders(608,608,3,19,19,29)\n",
    "Z = forward_pass(X)\n",
    "cost = cost_function(Z,y)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    acost = sess.run(cost,feed_dict={X:ax,y:ay})\n",
    "    print(acost[0])\n",
    "    print(acost[1])\n",
    "    print(acost[2])\n",
    "    print(acost[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
